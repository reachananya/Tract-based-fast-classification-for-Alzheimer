{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyYBwwel9HE-",
        "outputId": "f0dc1b25-679e-4014-f5fa-b8900f93c700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELofZnpTbGr3",
        "outputId": "cfb2b970-9a19-40f3-e13c-152638b9c412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Collecting fury\n",
            "  Downloading fury-0.9.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dipy\n",
            "  Downloading dipy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.23.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from fury) (3.9.1)\n",
            "Requirement already satisfied: pillow>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from fury) (9.4.0)\n",
            "Collecting pygltflib>=1.15.3 (from fury)\n",
            "  Downloading pygltflib-1.16.1.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from fury) (1.11.4)\n",
            "Collecting vtk>=9.1.0 (from fury)\n",
            "  Downloading vtk-9.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython!=0.29.29,>=0.29.24 in /usr/local/lib/python3.10/dist-packages (from dipy) (3.0.8)\n",
            "Requirement already satisfied: h5py>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from dipy) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from dipy) (4.66.1)\n",
            "Collecting trx-python>=0.2.9 (from dipy)\n",
            "  Downloading trx_python-0.2.9-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->fury) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->fury) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->fury) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->fury) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->fury) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->fury) (4.0.3)\n",
            "Collecting dataclasses-json>=0.0.25 (from pygltflib>=1.15.3->fury)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated (from pygltflib>=1.15.3->fury)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting setuptools-scm (from trx-python>=0.2.9->dipy)\n",
            "  Downloading setuptools_scm-8.0.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepdiff (from trx-python>=0.2.9->dipy)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nibabel\n",
            "  Downloading nibabel-5.2.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vtk>=9.1.0->fury) (3.7.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk>=9.1.0->fury) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk>=9.1.0->fury) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk>=9.1.0->fury) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk>=9.1.0->fury) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk>=9.1.0->fury) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk>=9.1.0->fury) (2.8.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.4->fury) (3.6)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff->trx-python>=0.2.9->dipy)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib>=1.15.3->fury) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->trx-python>=0.2.9->dipy) (4.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->trx-python>=0.2.9->dipy) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk>=9.1.0->fury) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pygltflib\n",
            "  Building wheel for pygltflib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygltflib: filename=pygltflib-1.16.1-py3-none-any.whl size=27085 sha256=c1a1d42a61d8b664e0083cc989d188f8e47abda8cb14e8ecd8898706cbabed45\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/73/91/ae3a93bb6cc6dde662ed1dc48dd0ec7ca41a7bcc2a1a99b5a6\n",
            "Successfully built pygltflib\n",
            "Installing collected packages: setuptools-scm, ordered-set, nibabel, mypy-extensions, marshmallow, deprecated, typing-inspect, deepdiff, vtk, trx-python, dataclasses-json, pygltflib, dipy, fury\n",
            "  Attempting uninstall: nibabel\n",
            "    Found existing installation: nibabel 4.0.2\n",
            "    Uninstalling nibabel-4.0.2:\n",
            "      Successfully uninstalled nibabel-4.0.2\n",
            "Successfully installed dataclasses-json-0.6.3 deepdiff-6.7.1 deprecated-1.2.14 dipy-1.8.0 fury-0.9.0 marshmallow-3.20.2 mypy-extensions-1.0.0 nibabel-5.2.0 ordered-set-4.1.0 pygltflib-1.16.1 setuptools-scm-8.0.4 trx-python-0.2.9 typing-inspect-0.9.0 vtk-9.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nibabel fury dipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRa_I06AeKN3",
        "outputId": "6bc740b5-563b-409d-d15e-05b7d376d23f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-f466099a7c23>:11: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import *\n",
        "import matplotlib.pyplot as plt\n",
        "import dipy.reconst.dki as dki\n",
        "import dipy.reconst.dti as dti\n",
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.data import get_fnames\n",
        "from dipy.io.gradients import read_bvals_bvecs\n",
        "from dipy.io.image import load_nifti\n",
        "from dipy.segment.mask import median_otsu\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from dipy.io.image import load_nifti, save_nifti\n",
        "import nibabel as nib\n",
        "from multiprocessing import Process, Queue\n",
        "import os\n",
        "import numba as nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOmvygQeErZu"
      },
      "outputs": [],
      "source": [
        "[X,Z,Y] = np.meshgrid(np.arange(-2,3),np.arange(-2,3),np.arange(-2,3))\n",
        "XYZ = np.stack([X,Y,Z])\n",
        "XYZ = XYZ.reshape(3,-1)\n",
        "XYZ = XYZ[None,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QyD_hIzEslu",
        "outputId": "8a960142-e2e8-473d-af35-e9ffe36bf687"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 3, 125)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XYZ.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f98fxwCvZ7ha"
      },
      "outputs": [],
      "source": [
        "def tf_subprocess(q):\n",
        "\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import Dense, Conv1D, Input, Reshape, InputLayer, Dropout,LayerNormalization,Flatten\n",
        "  import numpy as np\n",
        "  from tensorflow.keras import backend as kf\n",
        "  import matplotlib.pyplot as plt\n",
        "  import tensorflow as tf\n",
        "  from tensorflow.keras import Model\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "  [jj,outer_currSz,bsize,lidx11,Image_diff_norm,bvec,y_val0,y_val1,y_val2,y_val3,y_val4,y_val5,yCount] = q.get()\n",
        "\n",
        "  def rmse(yTrue, yPred):\n",
        "        return kf.sqrt(kf.mean(10 * kf.pow(yTrue - yPred, 2)))\n",
        "\n",
        "  def scaled_abs100(yTrue, yPred):\n",
        "      return 1000 * 100 * kf.mean(kf.abs((yTrue - yPred)))\n",
        "\n",
        "  def scaled_abs(yTrue, yPred):\n",
        "      #wt = tf.constant([[1.0],[100.0],[100.0]])\n",
        "      return 1000 * kf.mean(kf.abs((yTrue - yPred)))\n",
        "\n",
        "  model= tf.keras.models.load_model(\n",
        "      '21_diff_SwinTransformer_mode.tf', custom_objects={'scaled_abs': scaled_abs, 'scaled_abs100': scaled_abs100, 'rmse':rmse }, compile=True, options=None)\n",
        "\n",
        "  for jj0 in range(0,outer_currSz, bsize):\n",
        "    j0 = jj + jj0\n",
        "    upLim = min(jj0+bsize,outer_currSz)\n",
        "    currSz = upLim-jj0\n",
        "    X = np.zeros((currSz, lidx11.shape[2],Image_diff_norm.shape[3]))\n",
        "    for j1 in range(currSz):\n",
        "      j = j1+j0\n",
        "      for k in range(lidx11.shape[2]):\n",
        "        coord = lidx11[j,:,k].reshape((3,))\n",
        "        X[j1,k,:] = Image_diff_norm[coord[0],coord[1],coord[2],:]\n",
        "        ##########################\n",
        "      # x1FA = Image_diff_norm[idx1FA,:]\n",
        "    #X = X.transpose((0,2,1))\n",
        "    XX = np.zeros((currSz, 128, 100))\n",
        "    for i in range(X.shape[0]):\n",
        "      XX[i, :X.shape[1], :X.shape[2]] = X[i, :, :]\n",
        "      XX[i, X.shape[1]:, :X.shape[2]] = bvec.T\n",
        "    [yval0, yval1, yval2, yval3, yval4, yval5]= model.predict(XX,batch_size=2000) #batch_size=5\n",
        "    for j1 in range(currSz):\n",
        "      j = j1+j0\n",
        "      for k in range(lidx11.shape[2]):\n",
        "        coord = lidx11[j,:,k].reshape((3,))\n",
        "        y_val0[coord[0],coord[1],coord[2]] += yval0[j1, k]\n",
        "        y_val1[coord[0],coord[1],coord[2]] += yval1[j1, k]\n",
        "        y_val2[coord[0],coord[1],coord[2]] += yval2[j1, k]\n",
        "        y_val3[coord[0],coord[1],coord[2]] += yval3[j1, k]\n",
        "        y_val4[coord[0],coord[1],coord[2]] += yval4[j1, k]\n",
        "        y_val5[coord[0],coord[1],coord[2]] += yval5[j1, k]\n",
        "        yCount[coord[0],coord[1],coord[2]] += 1\n",
        "\n",
        "  #[yFA1, yAD1, yMD1]= model.predict(X,batch_size=batch_size)\n",
        "  q.put([y_val0, y_val1, y_val2, y_val3, y_val4, y_val5, yCount])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP5QWwwr9jDh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Input, Reshape, InputLayer, Dropout,LayerNormalization,Flatten\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as kf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def rmse(yTrue, yPred):\n",
        "      return kf.sqrt(kf.mean(10 * kf.pow(yTrue - yPred, 2)))\n",
        "\n",
        "def scaled_abs100(yTrue, yPred):\n",
        "    return 1000 * 100 * kf.mean(kf.abs((yTrue - yPred)))\n",
        "\n",
        "def scaled_abs(yTrue, yPred):\n",
        "    #wt = tf.constant([[1.0],[100.0],[100.0]])\n",
        "    return 1000 * kf.mean(kf.abs((yTrue - yPred)))\n",
        "\n",
        "model= tf.keras.models.load_model(\n",
        "    '21_diff_SwinTransformer_mode.tf', custom_objects={'scaled_abs': scaled_abs, 'scaled_abs100': scaled_abs100, 'rmse':rmse }, compile=True, options=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8b7-1bj_TOc"
      },
      "outputs": [],
      "source": [
        "param_path = '/content/drive/MyDrive/Ananya_Singhal_2010110087/ICIP - classification/AD_data_21diff'\n",
        "\n",
        "folderpath_labels = '/content/drive/MyDrive/Ananya_Singhal_2010110087/ICIP - classification/AD_data_21diff/DTI_parameters_21_Diff_AD'\n",
        "\n",
        "\n",
        "Testing = [\n",
        "'005_S_5038_M_82_AD_AD',\n",
        "'003_S_4152_M_61_AD_AD',\n",
        "'005_S_4910_F_82_AD_AD',\n",
        "'003_S_4892_F_75_AD_AD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0U1GChVHNWc",
        "outputId": "1ab6189b-3225-44b9-db0b-2de7c943596a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(256, 256, 59, 22)\n",
            "(22, 3)\n",
            "(21, 3) (21,)\n",
            "(256, 256, 59, 21)\n",
            "(260, 260, 63, 21)\n",
            "50/50 [==============================] - 9s 126ms/step\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "15/15 [==============================] - 3s 133ms/step\n",
            "(256, 256, 59, 22)\n",
            "(22, 3)\n",
            "(21, 3) (21,)\n",
            "(256, 256, 59, 21)\n",
            "(260, 260, 63, 21)\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "15/15 [==============================] - 2s 125ms/step\n",
            "(256, 256, 59, 22)\n",
            "(22, 3)\n",
            "(21, 3) (21,)\n",
            "(256, 256, 59, 21)\n",
            "(260, 260, 63, 21)\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "25/25 [==============================] - 3s 131ms/step\n",
            "(256, 256, 59, 22)\n",
            "(22, 3)\n",
            "(21, 3) (21,)\n",
            "(256, 256, 59, 21)\n",
            "(260, 260, 63, 21)\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "50/50 [==============================] - 6s 125ms/step\n",
            "35/35 [==============================] - 5s 130ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for lst in Testing:\n",
        "      file_path_test = os.path.join(param_path,'ordered_4d_image_21diff_{}.nii.gz'.format(lst, lst))\n",
        "\n",
        "      Maskfilepath = os.path.join(folderpath_labels,lst,'tensor_mask_{}.nii.gz'.format(lst))\n",
        "\n",
        "      for diff_count in [21]:    # 90, 64, 32, 21, 5\n",
        "\n",
        "\n",
        "            #fullpath = folderpath\n",
        "            fullpath= '/content/drive/MyDrive/Ananya_Singhal_2010110087/Code_Interpolation/'\n",
        "            fbval1 = os.path.join(fullpath,'100206_bvals1000_21_Diff.bval')\n",
        "            fbvec1 = os.path.join(fullpath,'100206_bvecs1000__21_Diff.bval')\n",
        "\n",
        "            bvals, bvecs = read_bvals_bvecs(fbval1, fbvec1)\n",
        "\n",
        "            data, affine = load_nifti(file_path_test) #loading ordered 4d test data\n",
        "            mask, _ = load_nifti(Maskfilepath) #loading mask\n",
        "            gtab = gradient_table(bvals, bvecs)\n",
        "\n",
        "            print(data.shape)\n",
        "            print(bvecs.shape)\n",
        "            diffusionGradientList= bvecs\n",
        "            noOfDiffusionComponent= bvecs.shape[0]\n",
        "\n",
        "            diffusionBVALSList= bvals\n",
        "            noOfBVALComponent= bvals.shape[0]\n",
        "\n",
        "            norm_of_diffusionGradientList = diffusionGradientList.__pow__(2).sum(1).__pow__(0.5)\n",
        "\n",
        "            # index_of_normalizing_bVecs = norm_of_diffusionGradientList < 1e-3\n",
        "            index_of_normalizing_bVecs = np.logical_and(diffusionBVALSList >=0,diffusionBVALSList <= 10)\n",
        "            indexList_diffGrad_B0 = np.arange(0, noOfDiffusionComponent)[index_of_normalizing_bVecs]\n",
        "            indexList_diffGrad = np.arange(0, noOfDiffusionComponent)[~index_of_normalizing_bVecs]\n",
        "\n",
        "            indexList_Bvals_B0 = np.arange(0, noOfBVALComponent)[index_of_normalizing_bVecs]\n",
        "            indexList_Bvals = np.arange(0, noOfBVALComponent)[~index_of_normalizing_bVecs]\n",
        "\n",
        "            bvec = bvecs[indexList_Bvals,:]\n",
        "            bval = bvals[indexList_Bvals]\n",
        "\n",
        "            print(bvec.shape, bval.shape)\n",
        "\n",
        "\n",
        "            Image_total = np.double(data)\n",
        "            Image_dim = Image_total.shape\n",
        "            Image_0 = Image_total[:, :, :, indexList_diffGrad_B0]\n",
        "            Image_diff = Image_total[:, :, :, indexList_diffGrad]\n",
        "            Image_S0_div = Image_0.sum(3) / indexList_diffGrad_B0.size\n",
        "\n",
        "            Image_S0_div_nonzeroIdx = np.reshape(np.array([Image_S0_div != 0]), Image_dim[0:3])\n",
        "\n",
        "            Image_diff_norm = np.zeros(Image_diff.shape)\n",
        "            Image_diff_norm[Image_S0_div_nonzeroIdx, :] = Image_diff[Image_S0_div_nonzeroIdx, :] / \\\n",
        "            Image_S0_div[Image_S0_div_nonzeroIdx][:, None]\n",
        "\n",
        "            Image_diff_norm_gt_1 = Image_diff_norm > 1\n",
        "            Image_diff_norm_lt_0 = Image_diff_norm < 0\n",
        "            Image_diff_norm[Image_diff_norm_gt_1] = 1\n",
        "            Image_diff_norm[Image_diff_norm_lt_0] = 0\n",
        "\n",
        "            print(Image_diff_norm.shape)\n",
        "            # X = Image_diff_norm.reshape((-1,Image_diff_norm.shape[3]))\n",
        "\n",
        "            Image_diff_norm = np.pad(Image_diff_norm, ((2, 2), (2, 2), (2, 2), (0, 0)))\n",
        "            mask = np.pad(mask, ((2, 2), (2, 2), (2, 2)))\n",
        "            print(Image_diff_norm.shape)\n",
        "\n",
        "            size = Image_diff_norm.shape\n",
        "\n",
        "            mask_idx = (mask>0)\n",
        "            mask_idx1 = mask_idx.reshape(-1)\n",
        "            # [X1,Z1,Y1] = np.meshgrid(np.arange(size[0]),np.arange(size[1]),np.arange(size[2]))\n",
        "            [X1,Y1,Z1] = np.meshgrid(np.arange(size[0]),np.arange(size[1]),np.arange(size[2]),indexing='ij')\n",
        "            imgidx = np.stack([X1,Y1,Z1])\n",
        "            imgidx = np.transpose(imgidx, axes = (1,2,3,0))\n",
        "            idx11 = imgidx.reshape((-1,3))\n",
        "            idx11 = idx11[mask_idx1, :]\n",
        "\n",
        "            ## Adding Neighbors #######\n",
        "            # idx11 = np.transpose(idx1FA.nonzero())\n",
        "            lidx11 = idx11[:,:,None] + XYZ ## get coordinates of neighbors\n",
        "\n",
        "            out_shape = tuple(i for i in Image_diff_norm.shape[0:3])\n",
        "\n",
        "            y_val0 = np.zeros(out_shape)\n",
        "            y_val1 = np.zeros(out_shape)\n",
        "            y_val2 = np.zeros(out_shape)\n",
        "            y_val3 = np.zeros(out_shape)\n",
        "            y_val4 = np.zeros(out_shape)\n",
        "            y_val5 = np.zeros(out_shape)\n",
        "            yCount = np.zeros(out_shape) + 1e-20\n",
        "\n",
        "            bsize = 100000\n",
        "            outer_bsize = bsize*3\n",
        "\n",
        "            for jj in range(0,lidx11.shape[0], outer_bsize):\n",
        "              outer_upLim = min(jj+outer_bsize,lidx11.shape[0])\n",
        "              outer_currSz = outer_upLim-jj\n",
        "              ##########################################\n",
        "              for jj0 in range(0,outer_currSz, bsize):\n",
        "                j0 = jj + jj0\n",
        "                upLim = min(jj0+bsize,outer_currSz)\n",
        "                currSz = upLim-jj0\n",
        "                X = np.zeros((currSz, lidx11.shape[2],Image_diff_norm.shape[3]))\n",
        "                for j1 in range(currSz):\n",
        "                  j = j1+j0\n",
        "                  for k in range(lidx11.shape[2]):\n",
        "                    coord = lidx11[j,:,k].reshape((3,))\n",
        "                    X[j1,k,:] = Image_diff_norm[coord[0],coord[1],coord[2],:]\n",
        "                    ##########################\n",
        "                  # x1FA = Image_diff_norm[idx1FA,:]\n",
        "                #X = X.transpose((0,2,1))\n",
        "                XX = np.zeros((currSz, 128, 100))\n",
        "                for i in range(X.shape[0]):\n",
        "                  XX[i, :X.shape[1], :X.shape[2]] = X[i, :, :]\n",
        "                  XX[i, X.shape[1]:, :X.shape[2]] = bvec.T\n",
        "                [yval0, yval1, yval2, yval3, yval4, yval5]= model.predict(XX,batch_size=2000) #batch_size=5\n",
        "                for j1 in range(currSz):\n",
        "                  j = j1+j0\n",
        "                  for k in range(lidx11.shape[2]):\n",
        "                    coord = lidx11[j,:,k].reshape((3,))\n",
        "                    y_val0[coord[0],coord[1],coord[2]] += yval0[j1, k]\n",
        "                    y_val1[coord[0],coord[1],coord[2]] += yval1[j1, k]\n",
        "                    y_val2[coord[0],coord[1],coord[2]] += yval2[j1, k]\n",
        "                    y_val3[coord[0],coord[1],coord[2]] += yval3[j1, k]\n",
        "                    y_val4[coord[0],coord[1],coord[2]] += yval4[j1, k]\n",
        "                    y_val5[coord[0],coord[1],coord[2]] += yval5[j1, k]\n",
        "                    yCount[coord[0],coord[1],coord[2]] += 1\n",
        "              ######## Create Subprocess ###############################################\n",
        "              # q = Queue()\n",
        "              # q.put([jj,outer_currSz,bsize,lidx11,Image_diff_norm,bvec,y_val0,y_val1,y_val2,y_val3,y_val4,y_val5,yCount])\n",
        "              # p = Process(target=tf_subprocess, args=(q,))\n",
        "              # p.start()\n",
        "              # p.join(timeout=300)\n",
        "              # [y_val0,y_val1,y_val2,y_val3,y_val4,y_val5,yCount] = q.get()\n",
        "              # q.close()\n",
        "              ########################################################################\n",
        "\n",
        "\n",
        "            y_val0 = (y_val0 / yCount) * mask\n",
        "            y_val1 = (y_val1 / yCount) * mask\n",
        "            y_val2 = (y_val2 / yCount) * mask\n",
        "            y_val3 = (y_val3 / yCount) * mask\n",
        "            y_val4 = (y_val4 / yCount) * mask\n",
        "            y_val5 = (y_val5 / yCount) * mask\n",
        "\n",
        "            y_val0 = y_val0[2:size[0]-2, 2:size[1]-2, 2:size[2]-2]\n",
        "            y_val1 = y_val1[2:size[0]-2, 2:size[1]-2, 2:size[2]-2]\n",
        "            y_val2 = y_val2[2:size[0]-2, 2:size[1]-2, 2:size[2]-2]\n",
        "            y_val3 = y_val3[2:size[0]-2, 2:size[1]-2, 2:size[2]-2]\n",
        "            y_val4 = y_val4[2:size[0]-2, 2:size[1]-2, 2:size[2]-2]\n",
        "            y_val5 = y_val5[2:size[0]-2, 2:size[1]-2, 2:size[2]-2]\n",
        "\n",
        "            tensor_val = np.stack((y_val0, y_val1, y_val2, y_val3, y_val4, y_val5), axis = 3)\n",
        "\n",
        "            # Reconstruct quantetative parameter back from tensor_val\n",
        "            D_est = dti.from_lower_triangular(tensor_val)\n",
        "            eigvals,eigvecs = dti.decompose_tensor(D_est, min_diffusivity=0)\n",
        "            tensor_fa = dti.fractional_anisotropy(eigvals)\n",
        "            tensor_md = dti.mean_diffusivity(eigvals)\n",
        "            tensor_rd = dti.radial_diffusivity(eigvals)\n",
        "            tensor_ad = dti.axial_diffusivity(eigvals, axis=-1)\n",
        "            OutputFolder = '/content/drive/MyDrive/Ananya_Singhal_2010110087/ICIP - classification/AD_data_21diff/pred_AD_results_21diff/Training_Patch5x5x5_Predict_FA_MD_RD_AD_volume_{}_Diff_for_SwinTransformer_5layer_ADNI_21_diff_additional'.format(diff_count)\n",
        "            # OutputFolder = '/content/drive/MyDrive/Ananya_Singhal_2010110087/21st_feb_Patch5x5x5_Predict_FA_MD_RD_AD_volume_{}_Diff_for_SwinTransformer_5layer_ADNI_21_diff_based_on_ver1'.format(diff_count)\n",
        "            # OutputFolder = '/media/snu/CT_DATA/cse_aiml_gdrive/AbhishekTiwari_at326/HCP_Young Adult_Data_Project/Patch3x3x3_Predict_FA_MD_AD_volume_90_Diff_for_SwinTransformer_3layer_Patch3x3x3_HCP_Youth_Adult_data_90_diff_64_diff_32_diff_21_diff_5_diff_upto10.tf'\n",
        "            if not os.path.exists(OutputFolder):\n",
        "              os.makedirs(os.path.join(OutputFolder,'FA'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'MD'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'RD'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'AD'))\n",
        "\n",
        "              os.makedirs(os.path.join(OutputFolder,'img0'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'img1'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'img2'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'img3'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'img4'))\n",
        "              os.makedirs(os.path.join(OutputFolder,'img5'))\n",
        "\n",
        "\n",
        "            fileFA = os.path.join(OutputFolder,'FA','FA_{}.nii.gz'.format(lst))\n",
        "            fileMD = os.path.join(OutputFolder,'MD','MD_{}.nii.gz'.format(lst))\n",
        "            fileRD = os.path.join(OutputFolder,'RD','RD_{}.nii.gz'.format(lst))\n",
        "            fileAD = os.path.join(OutputFolder,'AD','AD_,{}.nii.gz'.format(lst))\n",
        "\n",
        "            file_img0 = os.path.join(OutputFolder,'img0','img0_{}.nii.gz'.format(lst))\n",
        "            file_img1 = os.path.join(OutputFolder,'img1','img1_{}.nii.gz'.format(lst))\n",
        "            file_img2 = os.path.join(OutputFolder,'img2','img2_{}.nii.gz'.format(lst))\n",
        "            file_img3 = os.path.join(OutputFolder,'img3','img3_{}.nii.gz'.format(lst))\n",
        "            file_img4 = os.path.join(OutputFolder,'img4','img4_{}.nii.gz'.format(lst))\n",
        "            file_img5 = os.path.join(OutputFolder,'img5','img5_{}.nii.gz'.format(lst))\n",
        "\n",
        "            save_nifti(fileFA, tensor_fa.astype(np.float32), affine)\n",
        "            save_nifti(fileMD, tensor_md.astype(np.float32), affine)\n",
        "            save_nifti(fileRD, tensor_rd.astype(np.float32), affine)\n",
        "            save_nifti(fileAD, tensor_ad.astype(np.float32), affine)\n",
        "\n",
        "            save_nifti(file_img0, y_val0.astype(np.float32), affine)\n",
        "            save_nifti(file_img1, y_val1.astype(np.float32), affine)\n",
        "            save_nifti(file_img2, y_val2.astype(np.float32), affine)\n",
        "            save_nifti(file_img3, y_val3.astype(np.float32), affine)\n",
        "            save_nifti(file_img4, y_val4.astype(np.float32), affine)\n",
        "            save_nifti(file_img5, y_val5.astype(np.float32), affine)\n",
        "            # save_nifti(os.path.join(fullpath,'tensor_rd.nii.gz'), dti_RD.astype(np.float32), affine)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
